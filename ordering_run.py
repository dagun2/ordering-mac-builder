import os
import sys
import unicodedata
import traceback

import pandas as pd
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

def get_base_dir():
    if getattr(sys, 'frozen', False):
        exe_dir = os.path.dirname(sys.executable)
        return os.path.abspath(os.path.join(exe_dir, "../../../"))
    return os.path.dirname(os.path.abspath(__file__))

def normalize_url(url: str) -> str:
    return url.replace("http://", "").replace("https://", "").rstrip("/")

def main():
    log = ""
    error_log = ""

    try:
        # â”€â”€â”€ ê¸°ë³¸ ë””ë ‰í† ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        base_dir = get_base_dir()
        log += f"[ê²½ë¡œ] base_dir: {base_dir}\n"

        # â”€â”€â”€ ì—‘ì…€ íŒŒì¼ íƒìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        target_fname = unicodedata.normalize("NFC", "ë„¤ì´ë²„_ê²€ìƒ‰ì–´.xlsx")
        excel_path = os.path.join(base_dir, target_fname)
        log += f"ğŸ” ê²€ì‚¬ ì¤‘: {excel_path}\n"
        if not os.path.exists(excel_path):
            raise FileNotFoundError(f"{excel_path} ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        log += "âœ… íŒŒì¼ ë°œê²¬!\n"

        # â”€â”€â”€ ì—‘ì…€ ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        df = pd.read_excel(excel_path)
        log += f"ğŸ“ ì—‘ì…€ ë¡œë”© ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ\n"
        if "í‚¤ì›Œë“œ" not in df.columns or "ë§í¬" not in df.columns:
            raise ValueError("ì—‘ì…€ì— 'í‚¤ì›Œë“œ', 'ë§í¬' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # â”€â”€â”€ ì…€ë ˆë‹ˆì›€ & í¬ë¡¤ë§ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        target_classes = {
            "info_title",
            "link_tit",
            "link_question",
            "title_link",
            "fds-comps-right-image-text-title",
        }
        anchor_selector = ",".join(f"a[class*='{c}']" for c in target_classes)

        options = webdriver.ChromeOptions()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        driver = webdriver.Chrome(
            service=Service(ChromeDriverManager().install()), options=options
        )
        wait = WebDriverWait(driver, 10)

        results = []
        for idx, row in enumerate(df.itertuples(index=False), start=1):
            keyword = str(row.í‚¤ì›Œë“œ).strip()
            target_url = str(row.ë§í¬).strip()
            log += f"\n[{idx:>2}] âœ… í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘â€¦\n"

            # ë„¤ì´ë²„ ê²€ìƒ‰
            driver.get("https://www.naver.com")
            wait.until(EC.presence_of_element_located((By.NAME, "query")))
            box = driver.find_element(By.NAME, "query")
            box.clear()
            box.send_keys(keyword)
            box.send_keys(Keys.RETURN)

            # ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.api_subject_bx")))
            blocks = driver.find_elements(By.CSS_SELECTOR, "div.api_subject_bx")
            log += f"   â–¶ ê·¸ë£¹ ë¸”ë¡ {len(blocks)}ê°œ í™•ì¸\n"
            found = False

            for b_idx, block in enumerate(blocks, start=1):
                # ê·¸ë£¹ëª… ì¶”ì¶œ
                try:
                    group_title = block.find_element(By.CSS_SELECTOR, "h2.title").text.strip()
                except:
                    try:
                        group_title = block.find_element(
                            By.CSS_SELECTOR, "span.fds-comps-header-headline"
                        ).text.strip()
                    except:
                        group_title = "ê·¸ë£¹ëª… ì—†ìŒ"
                log += f"   [ê·¸ë£¹{b_idx}] {group_title}\n"

                anchors = block.find_elements(By.CSS_SELECTOR, anchor_selector)
                log += f"      Â· ì•µì»¤ {len(anchors)}ê°œ ì¶”ì¶œ\n"
                for rank, a in enumerate(anchors, start=1):
                    href = a.get_attribute("href") or ""
                    text = a.text.strip()
                    log += f"        {rank:>2}. {text} â†’ {href}\n"

                    if normalize_url(target_url) in normalize_url(href):
                        # ë“±ë¡ì¼ ì¶”ì¶œ
                        date_candidates = []
                        for sel in [
                            "div.profile_bx span.etc.date",
                            "div.user_info span.sub",
                            "span.etc.date",
                            "span.fds-info-sub-inner-text",
                        ]:
                            try:
                                val = block.find_element(By.CSS_SELECTOR, sel).text.strip()
                                date_candidates.append(val)
                            except:
                                pass
                        date_text = date_candidates[-1].rstrip(".") if date_candidates else "ë“±ë¡ì¼ ì—†ìŒ"
                        log += f"        â†’ ë§¤ì¹­! ìˆœìœ„={rank}, ë“±ë¡ì¼={date_text}\n"

                        results.append({
                            "í‚¤ì›Œë“œ": keyword,
                            "ë§í¬": href,
                            "ê·¸ë£¹ëª…": group_title,
                            "ê¸€ì œëª©": text,
                            "ë“±ë¡ì¼": date_text,
                            "ê¸ˆì¼ ìˆœìœ„": rank,
                        })
                        found = True
                        break
                if found:
                    break

            if not found:
                log += "        â†’ ë§¤ì¹­ëœ ê¸€ ì—†ìŒ\n"
                results.append({
                    "í‚¤ì›Œë“œ": keyword,
                    "ë§í¬": target_url,
                    "ê·¸ë£¹ëª…": "ìˆœìœ„ì— ì—†ìŒ",
                    "ê¸€ì œëª©": "ìˆœìœ„ì— ì—†ìŒ",
                    "ë“±ë¡ì¼": "ìˆœìœ„ì— ì—†ìŒ",
                    "ê¸ˆì¼ ìˆœìœ„": "ìˆœìœ„ì— ì—†ìŒ",
                })

        driver.quit()

        # â”€â”€â”€ ê²°ê³¼ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        out_dir = os.path.join(base_dir, "outputs")
        os.makedirs(out_dir, exist_ok=True)
        now = datetime.now().strftime("%Y%m%d_%H%M")
        out_path = os.path.join(out_dir, f"ë„¤ì´ë²„_ìˆœìœ„ì²´í¬_í¬ë¡¤ë§_{now}.xlsx")
        pd.DataFrame(results, columns=["í‚¤ì›Œë“œ","ë§í¬","ê·¸ë£¹ëª…","ê¸€ì œëª©","ë“±ë¡ì¼","ê¸ˆì¼ ìˆœìœ„"]) \
          .to_excel(out_path, index=False)
        log += f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {out_path}\n"

    except Exception as e:
        error_log += f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n"
        error_log += traceback.format_exc() + "\n"

    # â”€â”€â”€ ë¡œê·¸ ê¸°ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    # ê¸°ë³¸ ë¡œê·¸
    log_path = os.path.expanduser(f"~/naver_rank_{ts}_log.txt")
    with open(log_path, "w", encoding="utf-8") as f:
        f.write(log)
    print(f"\nğŸ“ ë¡œê·¸ ì €ì¥: {log_path}")

    # ì—ëŸ¬ ë¡œê·¸ê°€ ìˆìœ¼ë©´
    if error_log:
        err_path = os.path.expanduser(f"~/naver_rank_error_log.txt")
        with open(err_path, "a", encoding="utf-8") as f:
            f.write(f"\n[{ts}]\n")
            f.write(error_log)
        print(f"âš ï¸ ì—ëŸ¬ ë¡œê·¸ ê¸°ë¡: {err_path}")
        # macOS ì¼ ê²½ìš° Console.app ìœ¼ë¡œ ì—´ê¸°
        if sys.platform == "darwin":
            os.system(f"open '{err_path}'")

    # ì¢…ë£Œ ì½”ë“œ
    if error_log:
        sys.exit(1)

if __name__ == "__main__":
    main()
